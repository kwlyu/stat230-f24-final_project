---
title: "Final Project Code"
author: "Rebecca Hazen, Kunwu Lyu, and Jackson Rankin"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T, error=FALSE, message=FALSE, warning=FALSE)
library(tidyverse)
library(ggplot2)
library(GGally)
library(ggResidpanel)
library(broom)
library(patchwork)
library(purrr)
library(car)
library(corrplot)
library(MASS)
library(plotly)
library(gridExtra)
library(rlang)
```

## Data Wrangling

```{r Reading and Cleaning Data}
happiness_raw <- read_csv("GSS_commute_happiness.csv")

happiness_cleaned <- happiness_raw %>%
  select(year, happy, commute, realrinc, educ, race, gender1) %>% 
  filter(commute != ".i:  Inapplicable",
         realrinc > 0,
         happy != ".n:  No answer") %>% 
  mutate(
    educ = case_when(
      str_detect(educ, "grade") ~ as.numeric(str_extract(educ, "\\d+")),
      str_detect(educ, "college") ~ as.numeric(str_extract(educ, "\\d+")) + 12,
      str_detect(educ, "No formal schooling") ~ 0,
      TRUE ~ NA
    ),
    commute = if_else(str_detect(commute, "\\d+"), 
                      as.numeric(str_extract(commute, "\\d+")), NA),
    race = if_else(race == "White", "White", "Non White"),
    gender = if_else(gender1 == "MALE", "Male", "Female")
  ) %>% 
  select(-gender1) %>% 
  drop_na()

happiness_recode <- happiness_cleaned %>% 
  mutate(happy = if_else(happy == "Not too happy", 0, 1)) %>% 
  drop_na() 

write.csv(happiness_recode, file = "happiness_recode.csv")

# vars to iterate over later
quant_vars <- c("commute", "realrinc", "educ")
cat_vars <- c("gender", "race")
```

## EDA

```{r Distribution Plots}
ggpairs(happiness_cleaned)

# Boxplot for happiness by commute time
plot1 <- ggplot(happiness_cleaned, aes(x = happy, y = commute, fill = happy)) +
  geom_boxplot() +
  labs(title = "Commute Time Distribution by Happiness Level",  
       x = "Commute Time (minutes)", 
       fill = "Happiness Level")

# Boxplot of income by happiness level
plot2 <- ggplot(happiness_cleaned, aes(x = happy, y = realrinc, fill = happy)) +
  geom_boxplot() +
  labs(title = "Income Distribution by Happiness Level", 
       x = "Happiness Level", 
       y = "Real Income", 
       fill = "Happiness Level")

# Bar plot of happiness level by education level
plot3 <- ggplot(happiness_cleaned, aes(x = educ, fill = happy)) +
  geom_bar(position = "fill") +
  labs(title = "Proportion of Happiness Levels by Education Level", 
       x = "Education Level", 
       y = "Proportion", 
       fill = "Happiness Level") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Faceted bar plot for happiness levels by race and gender
plot4 <- ggplot(happiness_cleaned, aes(x = gender, fill = happy)) +
  geom_bar(position = "fill") +
  facet_wrap(~ race) +
  labs(title = "Proportion of Happiness by Race and Gender", 
       x = "Gender", 
       y = "Proportion", 
       fill = "Happiness Level")

plot5 <- ggplot(happiness_cleaned, aes(x = commute, fill = happy)) + 
  geom_bar(position = "fill") + 
  facet_wrap(~ gender)

# Arrange all plots in a 2x2 grid
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)
```

```{r Jitter Plots}
scatter_jitter_plots <- function(quant_vars, cat_vars, alpha = 0.5, jitter_width = 0.2, jitter_height = 0.2) {
  # Helper function to create a single scatterplot
  scatter_jitter_fn <- function(quant_var, cat_var) {
    # Convert variable names to symbols
    quant_sym <- rlang::sym(quant_var)
    cat_sym <- rlang::sym(cat_var)
    
    # Create the plot
    ggplot(happiness_recode, aes(x = !!quant_sym, y = happy, color = !!cat_sym)) +
      geom_jitter(width = jitter_width, height = jitter_height, alpha = alpha) +
      labs(
        y = "Happy",
        x = str_c(quant_var),
        color = cat_var
      ) +
      scale_y_continuous(breaks = c(0, 1))
  }
  
  # Initialize an empty list to store plots
  plot_list <- list()
  
  # Iterate over all combinations of quantitative and categorical variables
  for (quant_var in quant_vars) {
    for (cat_var in cat_vars) {
      # Generate the plot and store it in the list
      plot_name <- paste(quant_var, cat_var, sep = "_")
      plot_list[[plot_name]] <- scatter_jitter_fn(quant_var, cat_var)
    }
  }
  
  # Return the list of plots
  return(plot_list)
}

scatter_jitter_plots(quant_vars, cat_vars, alpha = 0.5, jitter_width = 0.2, jitter_height = 0.2)

```

```{r Empirical Log Odds}
empirical_log_odds_plot <- function(quant_vars, cat_vars, scale = "lin") {
  # Helper function to create a single plot
  empirical_plot_fn <- function(quant_var, cat_var, scale = "lin") {
    # Convert strings to symbols
    quant_group <- rlang::sym(quant_var)
    
    # Data transformation
    happiness_ag <- happiness_recode %>% 
      mutate(quant_grouped = ntile(!!quant_group, n = 8)) %>% 
      group_by(quant_grouped, !!rlang::sym(cat_var)) %>%  # Include categorical variable in grouping
      summarize(
        quant_grouped_med = median(!!quant_group), # Median of quant_var
        p = sum(happy == 1) / n(), # Proportion happy
        log_odds = log(p / (1 - p)), # Log odds
        .groups = "drop" # Avoid warning about grouping
      ) %>% 
      mutate(x_var = if (scale == "log") log(quant_grouped_med) else quant_grouped_med) # Add x_var based on scale
    
    # Set the x-axis label
    x_lab <- str_c(if (scale == "log") "Logged Grouped Median of " else "Grouped Median of ", quant_var)
    
    # Create the plot
    ggplot(happiness_ag, 
           aes(x = x_var, y = log_odds, color = !!rlang::sym(cat_var))) + 
      geom_point() +
      geom_smooth(method = "lm", se = FALSE) +
      labs(x = x_lab, y = "Empirical Log Odds", color = cat_var)
  }
  
  # Initialize an empty list to store plots
  plot_list <- list()
  
  # Loop over all combinations of quantitative and categorical variables
  for (quant_var in quant_vars) {
    for (cat_var in cat_vars) {
      # Generate the plot and store it in the list
      plot_name <- paste(quant_var, cat_var, sep = "_")
      plot_list[[plot_name]] <- empirical_plot_fn(quant_var, cat_var, scale)
    }
  }
  
  # Return the list of plots
  return(plot_list)
}

empirical_log_odds_plot(quant_vars = quant_vars, cat_vars = cat_vars, scale = "lin")
```

## Logistic Regression

```{r Interaction Model}
happiness_glm_base <- glm(happy ~ commute + realrinc + educ + race + gender, 
                     data = happiness_recode, family = binomial)
happiness_glm_int <- glm(happy ~ (commute + realrinc + educ) * race + gender, 
                     data = happiness_recode, family = binomial)

summary(happiness_glm_int)
vif(happiness_glm_base)

quant_resid_plot <- function(model = happiness_glm_int) {
  happiness_aug <- augment(model, data=happiness_recode,
                           type.residuals="pearson") %>% 
      mutate(commute_grps = ntile(happiness_recode$commute, n = 20),
             educ_grps = ntile(happiness_recode$educ, n = 20),
             realrinc_grps = ntile(happiness_recode$realrinc, n = 20))
  plots <- list()
  for (var in quant_vars) {
    group_col <- paste0(var, "_grps")
    group_name <- rlang::sym(group_col)
    
    happiness_quant_resid <- happiness_aug %>%
      group_by(!!group_name) %>%
      summarize(
        group_median = median(happiness_recode[[var]], na.rm = TRUE), # Median of the original variable
        resid_mean = mean(.resid, na.rm = TRUE) # Mean of residuals
      )
    
    p <- ggplot(happiness_quant_resid, aes(x = !!group_name, y = resid_mean)) +
      geom_point() +
      geom_hline(yintercept = 0, linetype="dotted") +
      labs(
        title = paste("Residuals vs", var),
        x = paste("Grouped ", var),
        y = "Mean Pearson Residual"
      )
    
    plots[[var]] <- p
  }
  return(plots)
}

quant_resid_plot()$commute | quant_resid_plot()$realrinc | quant_resid_plot()$educ
```

```{r Model Selection}
happiness_glm_int2 <- glm(happy ~ commute + (realrinc + educ) * race + gender, 
                     data = happiness_recode, family = binomial)

summary(happiness_glm_int2)

anova(happiness_glm_base, happiness_glm_int2, test = "LRT")
anova(happiness_glm_int, happiness_glm_int2, test = "LRT")

quant_resid_plot(happiness_glm_int2)
```

```{r Backward and Forward Selection, cache=TRUE, message=FALSE, warning=FALSE}
set.seed(67393937)

upper_model <- glm(happy ~ (commute + realrinc + educ + race + gender)^2,
                 data = happiness_recode, family = binomial)
lower_model <- glm(happy ~ 1, data = happiness_recode, family = binomial)

#backward selection
backwardSelectModel <- stepAIC(upper_model, scope = list(lower = lower_model, 
                                                         upper = upper_model),
                               direction = "backward")
summary(backwardSelectModel)

#forward selection
forwardSelectModel <- stepAIC(lower_model, scope = list(lower = lower_model, 
                                                         upper = upper_model),
                               direction = "forward")
summary(forwardSelectModel)

anova(happiness_glm_int2, backwardSelectModel, test = "LRT")
anova(happiness_glm_int2, forwardSelectModel, test = "LRT")
```

```{r Linear Combination}
compute_linear_combination <- function(model, coef_indices, conf_level = 0.95) {
  # Extract coefficients
  coef_values <- model$coefficients[coef_indices]
  
  # Point estimate
  linear_comb <- sum(coef_values)
  
  # Cov MTRX
  cov_matrix <- vcov(model)[coef_indices, coef_indices]
  
  # Joint SE
  linear_comb_se <- sqrt(sum(diag(cov_matrix)) + 
                           2 * sum(cov_matrix[lower.tri(cov_matrix)]))
  
  # Test statistic
  test_stat <- linear_comb / linear_comb_se
  
  # two sided p-val, normal dist
  p_value <- 2 * pnorm(abs(test_stat), lower.tail = FALSE)
  
  # CI
  z_value <- qnorm(1 - (1 - conf_level) / 2)
  conf_int <- linear_comb + c(-1, 1) * z_value * linear_comb_se
  
  # Untransformed response (exponential)
  untransformed <- exp(linear_comb)
  untransformed_ci <- exp(conf_int)
  
  # Return results as a list
  list(
    linear_comb = linear_comb,
    se = linear_comb_se,
    test_stat = test_stat,
    p_value = p_value,
    conf_int = conf_int,
    untransformed = untransformed,
    untransformed_ci = untransformed_ci
  )
}

exp(confint(happiness_glm_int2))

(Y_wht_est <- compute_linear_combination(
  model = happiness_glm_int2,
  coef_indices = c(3, 7),
  conf_level = 0.95
))

(edu_wht_est <- compute_linear_combination(
  model = happiness_glm_int2,
  coef_indices = c(4, 8),
  conf_level = 0.95
))
```


##### Becca's section


```{r}
#3# test
```


### Jackson's Section
### Model asumptions checking and fitting

```{r}
#Fit the basic model
happiness_glm <- glm(happy ~ commute + realrinc + educ + race + gender, 
                     data = happiness_recode, family = binomial)
summary(happiness_glm)
vif(happiness_glm)
happiness_aug1 <- augment(happiness_glm, data=happiness_recode,
                          type.residuals="pearson")

#EDA implies possible interaction between gender and commute time
  #and gender and education level, so test for that relationship
happiness_glm_gender<-
  glm(happy ~ commute*gender + realrinc+ + educ*gender + race, data=happiness_recode, family=binomial)
summary(happiness_glm_gender)
#Test for Interaction Term Significance
anova(happiness_glm, happiness_glm_gender)
  #Inclusion of interaction terms has no statistically discernible impact
    #on model explanatory power, continue with base model

#Base Model Assumption Analysis: Residual Plots
  #Bin by Commute Time
happiness_aug1$C_grps <- ntile(happiness_recode$commute, n = 20)
happiness_resid1 <- happiness_aug1 %>%
  group_by(C_grps) %>%
  summarize(C_grps_median = median(commute), # median D of groups
            resid_mean = mean(.resid)) # mean residual
    #Commute Residual Plot
ggplot(data=happiness_resid1, aes(x=C_grps, y=resid_mean))+
  geom_point()+
  geom_hline(yintercept=0, linetype="dotted")+
  labs(x="Commute Time (group average in minutes)", y="Mean Pearson Residual", 
       title="Figure 3: Pearson Residual Plot of Grouped Commute Time")

  #Bin by Education Level
happiness_aug1$E_grps <- ntile(happiness_recode$educ, n = 20)
happiness_resid1 <- happiness_aug1 %>%
  group_by(E_grps) %>%
  summarize(E_grps_median = median(educ), # median D of groups
            resid_mean = mean(.resid)) # mean residual
    #Education Residual Plot
ggplot(data=happiness_resid1, aes(x=E_grps, y=resid_mean))+
  geom_point()+
  geom_hline(yintercept=0, linetype="dotted")+
  labs(x="Education Level (group average)", y="Mean Pearson Residual", 
       title="Pearson Residual Plot of Grouped Education")

  #Bin by Income Level
happiness_aug1$Y_grps <- ntile(happiness_recode$realrinc, n = 20)
happiness_resid1 <- happiness_aug1 %>%
  group_by(Y_grps) %>%
  summarize(Y_grps_median = median(realrinc), # median D of groups
            resid_mean = mean(.resid)) # mean residual
    #Residual Plot of Income
ggplot(data=happiness_resid1, aes(x=Y_grps, y=resid_mean))+
  geom_point()+
  geom_hline(yintercept=0, linetype="dotted")+
  labs(x="Income (Group average dollars)", y="Mean Pearson Residual", 
       title="Pearson Residual Plot of Grouped Income")
```

### Analysis of Case Influence

```{r}
  #Analysis of Case Influence Statistics for Base Model
happiness_aug1 <- happiness_aug1 %>% mutate(case = row_number())

    #Check Cook's Distances
ggplot(happiness_aug1, aes(x=case, y=.cooksd))+
  geom_point()+
  labs(x="Index", y="Cook's Distance", 
       title="Cooks Distances for Model")#No apparent concerning values >1
which(happiness_aug1$.cooksd>.05)

  #Examine Leverage
ggplot(happiness_aug1, aes(x=case, y=.hat))+
  geom_point()+
  geom_hline(yintercept=6/874, linetype="dotted", color="red")+
  labs(x="Index", y="Leverage", title="Leverage for Original Model")
    #No particularly apparent outliers although many points above flagging range
which(happiness_aug1$.hat>6/874)
  #Don't consider studentized residuals because binary response, 
    #Wouldn't make sense and binning would be counterintuitive
```

### Maybe cut: analysis of alternative log model

```{r}
#EDA implies possible need to log both commute time and income to reduce skew
happiness_glm_refit<-
  glm(happy ~ log(commute+1) + log(realrinc+1) + educ + race +gender,
                         data=happiness_recode, family=binomial)
summary(happiness_glm_refit)
vif(happiness_glm_refit) #Looks good, suprisingly no problem with educ and Y
  
  #Augment regression and prepare binning for residual plots
happiness_aug<-augment(happiness_glm_refit, resid.type="pearson")
    #Commute
happiness_aug$CommuteGroups<-ntile(happiness_aug$`log(commute + 1)`, n=75)
happiness_aug_resid1<- happiness_aug %>%
  group_by(CommuteGroups) %>%
    summarize(CommuteGroupsMed = median(`log(commute + 1)`),
              resid_mean=mean(.resid), resid_med=median(.resid))
    #Education
happiness_aug$EducGroups<-ntile(happiness_aug$educ, n=75)
happiness_aug_resid2<- happiness_aug %>%
  group_by(EducGroups) %>%
    summarize(EducGroupsMed = median(educ),
              resid_mean=mean(.resid), resid_med=median(.resid))
    #Income
happiness_aug$YGroups<-ntile(happiness_aug$`log(realrinc + 1)`, n=75)
happiness_aug_resid3<- happiness_aug %>%
  group_by(YGroups) %>%
    summarize(YGroupsMed = median(`log(realrinc + 1)`),
              resid_mean=mean(.resid), resid_med=median(.resid))
  #Refit Model Assumption Checking: Residual Plots
    #Commute Time
ggplot(data=happiness_aug_resid1, aes(x=CommuteGroups, y=resid_mean))+
  geom_point()+
  geom_hline(yintercept=c(-2, 0, 2), linetype="dotted")+
  labs(x="Grouped Commute Times (minutes)", y="Mean Pearson Residual", 
       title="Residual Plot of Grouped Commute Time")
    #Education
ggplot(data=happiness_aug_resid2, aes(x=EducGroups, y=resid_mean))+
  geom_point()+
  geom_hline(yintercept=c(-2, 0, 2), linetype="dotted")+
  labs(x="Grouped Education levels", y="Mean Pearson Residual", 
       title="Residual Plot of Grouped Education Level")
    #Income
ggplot(data=happiness_aug_resid3, aes(x=YGroups, y=resid_mean))+
  geom_point()+
  geom_hline(yintercept=c(-2, 0, 2), linetype="dotted")+
  labs(x="Grouped Annual Income Levels (1986 dollars)", 
       y="Mean Pearson Residual", 
       title="Residual Plot of Grouped Income Level")
  #Across all plots general concern about possible outliers skew, 
    #Also very slight possible downward trend in Income plot

  #Analysis of Case Influence Statistics for Refit Model
happiness_aug <- happiness_aug %>% mutate(case = row_number())
    #Check Cook's Distances
ggplot(happiness_aug, aes(x=case, y=.cooksd))+
  geom_point()+
  labs(x="Index", y="Cook's Distance", 
       title="Cooks Distances for Model")#No apparent concerning values >1
    #Examine Studentized Residuals
ggplot(happiness_aug, aes(x=case, y=.std.resid))+
  geom_point()+
  geom_hline(yintercept=c(-3,3), linetype="dotted", color="red")+
  labs(x="Index", y="Studentized Residual", 
  title="Studentized Residuals for Original Model")
    #How to deal with this? Groups like previous?-->seems odd b/c looking for outliers
  #Examine Leverage
ggplot(happiness_aug, aes(x=case, y=.hat))+
  geom_point()+
  geom_hline(yintercept=6/874, linetype="dotted", color="red")+
  labs(x="Index", y="Leverage", title="Leverage for Original Model")
    #No particularly apparent outliers although many points above flagging range
which(happiness_aug$.hat>6/874)
  #Log model seems no better than base model is any respect, therefore use base
```

### Model Uncertainty Quantification

```{r}
#Model Uncertainty Quantification
summary(happiness_glm)
  #Generate Confidence Intervals
CIB0<-(1.220)+c(-1,1)*qnorm(0.975)*(0.6436)
CIB1<-(-0.001330)+c(-1,1)*qnorm(0.975)*(0.007519)
CIB2<-(0.0000373)+c(-1,1)*qnorm(0.975)*(0.0000118)
CIB3<-(0.-0.0002136)+c(-1,1)*qnorm(0.975)*(0.04631)
CIB4<-(0.01111)+c(-1,1)*qnorm(0.975)*(0.3323)
CIB5<-(0.7433)+c(-1,1)*qnorm(0.975)*(0.2509)
CIB0
CIB1
CIB2
CIB3
CIB4
CIB5
```

